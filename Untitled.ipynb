{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy\n",
    "import pandas\n",
    "import nltk\n",
    "import ssl\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn import model_selection\n",
    "from joblib import dump, load\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Importing the dataset\n",
    "\n",
    "print('Ingesting the data...\\n')\n",
    "train = pandas.read_csv('data/train.txt', delimiter = '\\t', header = None, quoting = 3)\n",
    "train.columns = ['Review', 'Rating']\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('all', quiet = True)\n",
    "\n",
    "print('Creating the bag of words...\\n')\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, train.shape[0]):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "# Creating the Bag of Words model using CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = train.iloc[:, 1].values\n",
    "\n",
    "clf_01 = KNeighborsClassifier()\n",
    "clf_02 = RandomForestClassifier()\n",
    "clf_03 = GaussianNB()\n",
    "clf_04 = BernoulliNB(alpha=0.8)\n",
    "clf_05 = MultinomialNB(alpha=0.1)\n",
    "clf_06 = LogisticRegression(C=1.5)\n",
    "clf_07 = DecisionTreeClassifier()\n",
    "clf_08 = SVC(kernel=\"linear\")\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers = [clf_01, clf_02, clf_03],\n",
    "                         meta_classifier = lr,\n",
    "                         use_probas = True,\n",
    "                         average_probas = False)\n",
    "\n",
    "print('Performing 5-fold cross validation modelling...\\n')\n",
    "\n",
    "results = []\n",
    "\n",
    "for clf, label in zip([clf_01, clf_02, clf_03, clf_04, clf_05, clf_06, clf_07, clf_08, sclf],\n",
    "                     ['KNN',\n",
    "                     'Random Forest',\n",
    "                     'Gaussian Naive Bayes',\n",
    "                     'Bernoulli Naive Bayes',\n",
    "                     'Multinomial Naive Bayes',\n",
    "                     'Logistic Regression',\n",
    "                     'Decision Tree Classifier',\n",
    "                     'Support Vector Machine',\n",
    "                     'Stacked Classifier']):\n",
    "    scores = model_selection.cross_val_score(clf, X, y, cv = 5, scoring = 'accuracy')\n",
    "    print('Accuracy: %0.6f (+/- %0.2f) [%s]'\n",
    "         % (scores.mean(), scores.std(), label))\n",
    "    results.append([label, scores.mean(), scores.std(), clf])\n",
    "\n",
    "def maximum_accuracy(sequence):\n",
    "    if not sequence:\n",
    "        raise ValueError('empty sequence')\n",
    "\n",
    "    maximum = sequence[0]\n",
    "\n",
    "    for item in sequence:\n",
    "        # Compare elements by their weight stored\n",
    "        # in their second element.\n",
    "        if item[1] > maximum[1]:\n",
    "            maximum = item\n",
    "\n",
    "    return maximum\n",
    "\n",
    "best_model = maximum_accuracy(results)\n",
    "best_model[3].fit(X, y)\n",
    "print('\\nThe optimal model was the ' + best_model[0] + ' with an accuracy of ' + str(round(best_model[1], 2)))\n",
    "print('\\n')\n",
    "print('Ingesting the test data...\\n')\n",
    "test = pandas.read_csv('data/test.txt', delimiter = '\\t', header = None, quoting = 3)\n",
    "test.columns = ['Review']\n",
    "\n",
    "print('Applying the bag of words...\\n')\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, test.shape[0]):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "# Creating the Bag of Words model using CountVectorizer\n",
    "\n",
    "X_test = cv.transform(corpus).toarray()\n",
    "test['Predictions'] = best_model[3].predict(X_test)\n",
    "test['Confidence of Positive (1)'] = [i[1] for i in best_model[3].predict_proba(X_test)]\n",
    "print(test)\n",
    "test.to_csv('data/test_predictions.txt', index=None, sep='\\t')\n",
    "print('\\nResults written out to data/test_predictions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting the data...\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "Performing 5-fold cross validation modelling...\n",
      "\n",
      "Accuracy: 0.671517 (+/- 0.04) [KNN]\n",
      "Accuracy: 0.745710 (+/- 0.05) [Random Forest]\n",
      "Accuracy: 0.676704 (+/- 0.02) [Gaussian Naive Bayes]\n",
      "Accuracy: 0.765448 (+/- 0.02) [Bernoulli Naive Bayes]\n",
      "Accuracy: 0.757054 (+/- 0.02) [Multinomial Naive Bayes]\n",
      "Accuracy: 0.771736 (+/- 0.03) [Logistic Regression]\n",
      "Accuracy: 0.706039 (+/- 0.04) [Decision Tree Classifier]\n",
      "Accuracy: 0.757201 (+/- 0.04) [Support Vector Machine]\n",
      "Accuracy: 0.761259 (+/- 0.03) [Stacked Classifier]\n",
      "\n",
      "The optimal model was the Logistic Regression with an accuracy of 0.77\n",
      "\n",
      "\n",
      "Ingesting the test data...\n",
      "\n",
      "Applying the bag of words...\n",
      "\n",
      "                                               Review  Predictions  \\\n",
      "0   There was a warm feeling with the service and ...            1   \n",
      "1   An extensive menu provides lots of options for...            1   \n",
      "2   I always order from the vegetarian menu during...            0   \n",
      "3   I have watched their prices inflate, portions ...            1   \n",
      "4   Wonderful lil tapas and the ambience made me f...            1   \n",
      "5   I got to enjoy the seafood salad, with a fabul...            0   \n",
      "6   The wontons were thin, not thick and chewy, al...            0   \n",
      "7   Level 5 spicy was perfect, where spice didn't ...            0   \n",
      "8   We were sat right on time and our server from ...            1   \n",
      "9   Main thing I didn't enjoy is that the crowd is...            1   \n",
      "10  When I'm on this side of town, this will defin...            1   \n",
      "11  I had to wait over 30 minutes to get my drink ...            0   \n",
      "12                      This is a GREAT place to eat!            0   \n",
      "13                  The jalapeno bacon is soooo good.            1   \n",
      "14         The service was poor and thats being nice.            0   \n",
      "15  Food was good, service was good, Prices were g...            0   \n",
      "16  The place was not clean and the food oh so stale!            1   \n",
      "17  The chicken dishes are OK, the beef is like sh...            0   \n",
      "18                    But the service was beyond bad.            0   \n",
      "19                        I'm so happy to be here!!!\"            0   \n",
      "20                                  Tasted like dirt.            0   \n",
      "21  One of the few places in Phoenix that I would ...            1   \n",
      "22                             The block was amazing.            1   \n",
      "23  It's close to my house, it's low-key, non-fanc...            1   \n",
      "24  * Both the Hot & Sour & the Egg Flower Soups w...            1   \n",
      "25  My sashimi was poor quality being soggy and ta...            1   \n",
      "26      Great time - family dinner on a Sunday night.            0   \n",
      "27  the food is not tasty at all, not to say its \"...            1   \n",
      "28          What did bother me, was the slow service.            0   \n",
      "29       The flair bartenders are absolutely amazing!            0   \n",
      "30  Their frozen margaritas are WAY too sugary for...            1   \n",
      "31          These were so good we ordered them twice.            0   \n",
      "32  So in a nutshell: 1) The restaraunt smells lik...            1   \n",
      "33                 My girlfriend's veal was very bad.            0   \n",
      "34                    Unfortunately, it was not good.            1   \n",
      "35               I had a pretty satifying experience.            1   \n",
      "36    Join the club and get awesome offers via email.            1   \n",
      "37  Perfect for someone (me) who only likes beer i...            0   \n",
      "38  Bland and flavorless is a good way of describi...            1   \n",
      "39  The chains, which I'm no fan of, beat this pla...            0   \n",
      "40                        The nachos are a MUST HAVE!            1   \n",
      "\n",
      "    Confidence of Positive (1)  \n",
      "0                     0.926737  \n",
      "1                     0.558892  \n",
      "2                     0.313127  \n",
      "3                     0.961884  \n",
      "4                     0.980120  \n",
      "5                     0.175575  \n",
      "6                     0.410314  \n",
      "7                     0.266225  \n",
      "8                     0.935690  \n",
      "9                     0.960200  \n",
      "10                    0.571155  \n",
      "11                    0.141355  \n",
      "12                    0.163498  \n",
      "13                    0.825939  \n",
      "14                    0.110803  \n",
      "15                    0.154586  \n",
      "16                    0.717944  \n",
      "17                    0.173160  \n",
      "18                    0.324126  \n",
      "19                    0.433166  \n",
      "20                    0.249203  \n",
      "21                    0.787105  \n",
      "22                    0.728031  \n",
      "23                    0.854933  \n",
      "24                    0.571413  \n",
      "25                    0.894283  \n",
      "26                    0.151058  \n",
      "27                    0.996906  \n",
      "28                    0.035857  \n",
      "29                    0.114754  \n",
      "30                    0.696554  \n",
      "31                    0.219577  \n",
      "32                    0.741072  \n",
      "33                    0.188584  \n",
      "34                    0.654112  \n",
      "35                    0.679874  \n",
      "36                    0.913102  \n",
      "37                    0.153465  \n",
      "38                    0.923195  \n",
      "39                    0.211519  \n",
      "40                    0.714236  \n",
      "Results written out to data/train_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "print('Ingesting the data...\\n')\n",
    "train = pandas.read_csv('data/train.txt', delimiter = '\\t', header = None, quoting = 3)\n",
    "train.columns = ['Review', 'Rating']\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('all', quiet = True)\n",
    "\n",
    "print('Creating the bag of words...\\n')\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, train.shape[0]):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "# Creating the Bag of Words model using CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = train.iloc[:, 1].values\n",
    "\n",
    "clf_01 = KNeighborsClassifier()\n",
    "clf_02 = RandomForestClassifier()\n",
    "clf_03 = GaussianNB()\n",
    "clf_04 = BernoulliNB(alpha=0.8)\n",
    "clf_05 = MultinomialNB(alpha=0.1)\n",
    "clf_06 = LogisticRegression(C=1.5)\n",
    "clf_07 = DecisionTreeClassifier()\n",
    "clf_08 = SVC(kernel=\"linear\")\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers = [clf_01, clf_02, clf_03],\n",
    "                         meta_classifier = lr,\n",
    "                         use_probas = True,\n",
    "                         average_probas = False)\n",
    "\n",
    "print('Performing 5-fold cross validation modelling...\\n')\n",
    "\n",
    "results = []\n",
    "\n",
    "for clf, label in zip([clf_01, clf_02, clf_03, clf_04, clf_05, clf_06, clf_07, clf_08, sclf],\n",
    "                     ['KNN',\n",
    "                     'Random Forest',\n",
    "                     'Gaussian Naive Bayes',\n",
    "                     'Bernoulli Naive Bayes',\n",
    "                     'Multinomial Naive Bayes',\n",
    "                     'Logistic Regression',\n",
    "                     'Decision Tree Classifier',\n",
    "                     'Support Vector Machine',\n",
    "                     'Stacked Classifier']):\n",
    "    scores = model_selection.cross_val_score(clf, X, y, cv = 5, scoring = 'accuracy')\n",
    "    print('Accuracy: %0.6f (+/- %0.2f) [%s]'\n",
    "         % (scores.mean(), scores.std(), label))\n",
    "    results.append([label, scores.mean(), scores.std(), clf])\n",
    "\n",
    "def maximum_accuracy(sequence):\n",
    "    if not sequence:\n",
    "        raise ValueError('empty sequence')\n",
    "\n",
    "    maximum = sequence[0]\n",
    "\n",
    "    for item in sequence:\n",
    "        # Compare elements by their weight stored\n",
    "        # in their second element.\n",
    "        if item[1] > maximum[1]:\n",
    "            maximum = item\n",
    "\n",
    "    return maximum\n",
    "\n",
    "best_model = maximum_accuracy(results)\n",
    "best_model[3].fit(X, y)\n",
    "print('\\nThe optimal model was the ' + best_model[0] + ' with an accuracy of ' + str(round(best_model[1], 2)))\n",
    "print('\\n')\n",
    "print('Ingesting the test data...\\n')\n",
    "test = pandas.read_csv('data/test.txt', delimiter = '\\t', header = None, quoting = 3)\n",
    "test.columns = ['Review']\n",
    "\n",
    "print('Applying the bag of words...\\n')\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, test.shape[0]):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "# Creating the Bag of Words model using CountVectorizer\n",
    "\n",
    "X_test = cv.transform(corpus).toarray()\n",
    "test['Predictions'] = best_model[3].predict(X_test)\n",
    "test['Confidence of Positive (1)'] = [i[1] for i in best_model[3].predict_proba(X_test)]\n",
    "print(test)\n",
    "test.to_csv('data/test_predictions.txt', index=None, sep='\\t')\n",
    "print('\\nResults written out to data/test_predictions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting the test data...\n",
      "\n",
      "Applying the bag of words...\n",
      "\n",
      "                                               Review  Predictions  \\\n",
      "0   There was a warm feeling with the service and ...            0   \n",
      "1   An extensive menu provides lots of options for...            1   \n",
      "2   I always order from the vegetarian menu during...            1   \n",
      "3   I have watched their prices inflate, portions ...            0   \n",
      "4   Wonderful lil tapas and the ambience made me f...            1   \n",
      "5   I got to enjoy the seafood salad, with a fabul...            0   \n",
      "6   The wontons were thin, not thick and chewy, al...            1   \n",
      "7   Level 5 spicy was perfect, where spice didn't ...            1   \n",
      "8   We were sat right on time and our server from ...            1   \n",
      "9   Main thing I didn't enjoy is that the crowd is...            1   \n",
      "10  When I'm on this side of town, this will defin...            1   \n",
      "11  I had to wait over 30 minutes to get my drink ...            0   \n",
      "12                      This is a GREAT place to eat!            1   \n",
      "13                  The jalapeno bacon is soooo good.            1   \n",
      "14         The service was poor and thats being nice.            1   \n",
      "15  Food was good, service was good, Prices were g...            1   \n",
      "16  The place was not clean and the food oh so stale!            1   \n",
      "17  The chicken dishes are OK, the beef is like sh...            1   \n",
      "18                    But the service was beyond bad.            0   \n",
      "19                        I'm so happy to be here!!!\"            1   \n",
      "20                                  Tasted like dirt.            0   \n",
      "21  One of the few places in Phoenix that I would ...            0   \n",
      "22                             The block was amazing.            1   \n",
      "23  It's close to my house, it's low-key, non-fanc...            1   \n",
      "24  * Both the Hot & Sour & the Egg Flower Soups w...            0   \n",
      "25  My sashimi was poor quality being soggy and ta...            0   \n",
      "26      Great time - family dinner on a Sunday night.            1   \n",
      "27  the food is not tasty at all, not to say its \"...            0   \n",
      "28          What did bother me, was the slow service.            0   \n",
      "29       The flair bartenders are absolutely amazing!            1   \n",
      "30  Their frozen margaritas are WAY too sugary for...            0   \n",
      "31          These were so good we ordered them twice.            1   \n",
      "32  So in a nutshell: 1) The restaraunt smells lik...            0   \n",
      "33                 My girlfriend's veal was very bad.            0   \n",
      "34                    Unfortunately, it was not good.            1   \n",
      "35               I had a pretty satifying experience.            0   \n",
      "36    Join the club and get awesome offers via email.            1   \n",
      "37  Perfect for someone (me) who only likes beer i...            1   \n",
      "38  Bland and flavorless is a good way of describi...            0   \n",
      "39  The chains, which I'm no fan of, beat this pla...            1   \n",
      "40                        The nachos are a MUST HAVE!            0   \n",
      "\n",
      "    Confidence of Positive (1)  \n",
      "0                     0.274327  \n",
      "1                     0.733176  \n",
      "2                     0.594820  \n",
      "3                     0.421923  \n",
      "4                     0.826122  \n",
      "5                     0.399519  \n",
      "6                     0.501388  \n",
      "7                     0.734893  \n",
      "8                     0.832746  \n",
      "9                     0.676966  \n",
      "10                    0.920805  \n",
      "11                    0.061591  \n",
      "12                    0.926507  \n",
      "13                    0.900231  \n",
      "14                    0.659056  \n",
      "15                    0.988889  \n",
      "16                    0.500276  \n",
      "17                    0.621229  \n",
      "18                    0.161611  \n",
      "19                    0.760613  \n",
      "20                    0.373537  \n",
      "21                    0.219081  \n",
      "22                    0.818985  \n",
      "23                    0.648470  \n",
      "24                    0.379687  \n",
      "25                    0.016755  \n",
      "26                    0.955898  \n",
      "27                    0.384076  \n",
      "28                    0.073188  \n",
      "29                    0.863645  \n",
      "30                    0.308060  \n",
      "31                    0.839980  \n",
      "32                    0.335439  \n",
      "33                    0.114602  \n",
      "34                    0.632759  \n",
      "35                    0.479818  \n",
      "36                    0.682771  \n",
      "37                    0.735585  \n",
      "38                    0.073687  \n",
      "39                    0.682460  \n",
      "40                    0.353928  \n"
     ]
    }
   ],
   "source": [
    "print('Ingesting the test data...\\n')\n",
    "test = pandas.read_csv('data/test.txt', delimiter = '\\t', header = None, quoting = 3)\n",
    "test.columns = ['Review']\n",
    "\n",
    "print('Applying the bag of words...\\n')\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, test.shape[0]):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "# Creating the Bag of Words model using CountVectorizer\n",
    "\n",
    "X_test = cv.transform(corpus).toarray()\n",
    "test['Predictions'] = best_model[3].predict(X_test)\n",
    "test['Confidence of Positive (1)'] = [i[1] for i in best_model[3].predict_proba(X_test)]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "gs = gridspec.GridSpec(3, 3)\n",
    "\n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "\n",
    "for clf, lab, grd in zip([clf_01, clf_02, clf_03, clf_04, clf_05, clf_06, clf_07, clf_08, sclf],\n",
    "                        ['KNN',\n",
    "                        'Random Forest',\n",
    "                        'Gaussian Naive Bayes',\n",
    "                        'Bernoulli Naive Bayes',\n",
    "                        'Multinomial Naive Bayes',\n",
    "                        'Logistic Regression',\n",
    "                        'Decision Tree Classifier',\n",
    "                        'Support Vector Machine',\n",
    "                        'Stacked Classifier'],\n",
    "                        itertools.product([0, 1], repeat = 2)):\n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X = X, y = y, clf = clf)\n",
    "    plt.title(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare configuration for cross validation test harness\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
